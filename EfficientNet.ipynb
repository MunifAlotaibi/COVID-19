{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EfficientNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MunifAlotaibi/COVID-19/blob/master/EfficientNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B0vLWow7A98D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "7b6da0c6-4f44-48ca-f061-b6a20f6ee595"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCEUD39bd2Ch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Hc3ZpMReXtW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0532a945-0bb5-427b-8b6d-b848deb14ed3"
      },
      "source": [
        "cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0I5S3W9CqZP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "00319c3f-66ae-40d6-d7d0-7cbc9c037913"
      },
      "source": [
        "cd 'drive/My Drive'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Qg465VkB1sb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import glob\n",
        "import numpy as np\n",
        "import cv2\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "MEAN_RGB = [0.485 * 255, 0.456 * 255, 0.406 * 255]\n",
        "STDDEV_RGB = [0.229 * 255, 0.224 * 255, 0.225 * 255]\n",
        "\n",
        "\n",
        "def preprocess_input(x):\n",
        "    assert x.ndim in (3, 4)\n",
        "    assert x.shape[-1] == 3\n",
        "\n",
        "    x = x - np.array(MEAN_RGB)\n",
        "    x = x / np.array(STDDEV_RGB)\n",
        "\n",
        "    return x\n",
        "\n",
        "image_list = []\n",
        "labels = []\n",
        "dim = (250,250)\n",
        "#dim = (120,120)\n",
        "\n",
        "\n",
        "for filename in os.listdir('X-RayImageDataSet/Covid-19'):\n",
        "    im = cv2.imread(os.path.join('X-RayImageDataSet/Covid-19',filename))\n",
        "    im = cv2.resize(im, dim)\n",
        "    #im = center_crop_and_resize(im, dim)\n",
        "    im  = np.asarray(im)\n",
        "    im = preprocess_input(im)\n",
        "    image_list.append(im)\n",
        "    labels.append(0)\n",
        "\n",
        "for filename in os.listdir('X-RayImageDataSet/Pneumonia'):\n",
        "    im = cv2.imread(os.path.join('X-RayImageDataSet/Pneumonia',filename))\n",
        "    im = cv2.resize(im, dim)\n",
        "    #im = center_crop_and_resize(im, dim)\n",
        "    im  = np.asarray(im)\n",
        "    im = preprocess_input(im)\n",
        "    image_list.append(im)\n",
        "    labels.append(1)\n",
        "    \n",
        "for filename in os.listdir('X-RayImageDataSet/Nofindings'):\n",
        "    im = cv2.imread(os.path.join('X-RayImageDataSet/Nofindings',filename))\n",
        "    im = cv2.resize(im, dim)\n",
        "    #im = center_crop_and_resize(im, dim)\n",
        "    im  = np.asarray(im)\n",
        "    im = preprocess_input(im)\n",
        "    image_list.append(im)\n",
        "    labels.append(2)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tARCPntqV7v6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68b6784b-d4f3-41b4-eccc-6ed5f558f1b3"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "tf.__version__\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mglP3BQb_Mc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "c1ddd848-59de-467d-c5f4-3a128445703b"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "image_size = (150, 150)\n",
        "batch_size = 32\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    'PetImages', validation_split=0.2, subset='training', seed=1337,\n",
        "    image_size=image_size, batch_size=batch_size)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-a1158d210d23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;34m'PetImages'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1337\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     image_size=image_size, batch_size=batch_size)\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.keras.preprocessing' has no attribute 'image_dataset_from_directory'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOmITJIhemk_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "c3201a23-57b1-4df5-b4f3-a0cfd5ac6dc8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 1125 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAdr3ysBfZeN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d088ccde-4bcf-4cd4-ce0c-6e93c12a1cc2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function int.to_bytes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vT3aDJwmWcgN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "963039c7-1a06-441e-8b5f-f28d92c8ba07"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-2362e83cc27f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# fits the model on batches with real-time data augmentation:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m model.fit_generator(datagen.flow(image_list, labels, batch_size=32),\n\u001b[0m\u001b[1;32m     17\u001b[0m                     samples_per_epoch=len(X_train), nb_epoch=nb_epoch)\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ETHwvjf1UNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H34dYem3DDdU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    image_list, labels, test_size=0.20, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhUeFKVJDEqC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "be5d64f1-a4ea-48cd-e23b-5bf54f6b2e91"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (900, 150, 150, 3)\n",
            "900 train samples\n",
            "225 test samples\n",
            "(900, 150, 150, 3)\n",
            "(900,)\n",
            "(225, 150, 150, 3)\n",
            "(225,)\n",
            "==============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4iQJsZaDKR0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "513d1eac-41ae-4ade-c324-f83ea45593af"
      },
      "source": [
        "!git clone https://github.com/Tony607/efficientnet_keras_transfer_learning\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'efficientnet_keras_transfer_learning' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AftRmFfzDPoG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c501d76-4f0a-47d2-9ce1-29a2443c3008"
      },
      "source": [
        "%cd efficientnet_keras_transfer_learning/\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/efficientnet_keras_transfer_learning\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PyZXbsIYBXT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1495310f-1d06-4d62-e783-4bc065b0cb90"
      },
      "source": [
        "\n",
        "\n",
        "from keras.layers import Conv1D, Input, AveragePooling1D\n",
        "from keras.models import Model\n",
        "\n",
        "import keras\n",
        "#from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "#from keras import backend as K\n",
        "from keras.layers import Conv1D, MaxPooling1D"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGD3uA6PDoDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = (250, 250 ,3)\n",
        "\n",
        "classes = 3\n",
        "num_epochs = 2\n",
        "\n",
        "    # create input tensor\n",
        "x_input = Input(input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3c0NWp6DVQE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "7081fdeb-13b3-4cd4-f69e-121b39fc1085"
      },
      "source": [
        "from efficientnet import EfficientNetB3 as EfficientNetB2\n",
        "from efficientnet import center_crop_and_resize, preprocess_input\n",
        "\n",
        "conv_base = EfficientNetB2(include_top=False, input_shape=input_shape, weights=\"imagenet\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b3_imagenet_1000_notop.h5\n",
            "43974656/43966704 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kiCzQZYW4so8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMUnNR8SCwbx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "20e0014b-ca6c-4c4b-9948-b0b388bb2a2f"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-caf532d1d94f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_custom_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mget_custom_objects\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'swish_act'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSwishActivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mswish_act\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'swish_act' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcLJq-_0IHtK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbyHjB9neZWx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "outputId": "d2e159fd-d0c9-4439-f1d1-a39b2e6e094c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "efficientnet-b3 (Model)      (None, 5, 5, 1536)        10783528  \n",
            "_________________________________________________________________\n",
            "gap (GlobalMaxPooling2D)     (None, 1536)              0         \n",
            "_________________________________________________________________\n",
            "dropout_out (Dropout)        (None, 1536)              0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 200)               307400    \n",
            "_________________________________________________________________\n",
            "fc_out (Dense)               (None, 3)                 603       \n",
            "=================================================================\n",
            "Total params: 11,091,531\n",
            "Trainable params: 11,004,235\n",
            "Non-trainable params: 87,296\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5nSv-gZNNQk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "07bffcb6-4b24-4944-eeef-a1f5675da68f"
      },
      "source": [
        "conv_base.trainable = True\n",
        "\n",
        "set_trainable = False\n",
        "for layer in conv_base.layers:\n",
        "    if layer.name == 'multiply_16':\n",
        "        set_trainable = True\n",
        "    if set_trainable:\n",
        "        layer.trainable = True\n",
        "    else:\n",
        "        layer.trainable = True\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-03415e42a24f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconv_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mset_trainable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mconv_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'multiply_16'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'conv_base' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hV9ujRPwe1NY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "outputId": "7ea24383-bed8-4c16-c06d-f63cd615d00c"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-a5dc1806ee63>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    813\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 815\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, shuffle, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m         **kwargs)\n\u001b[0m\u001b[1;32m    909\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, workers, use_multiprocessing, max_queue_size, model, **kwargs)\u001b[0m\n\u001b[1;32m    770\u001b[0m     \u001b[0;31m# Since we have to know the dtype of the python generator when we build the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m     \u001b[0;31m# dataset, we have to look at a batch to infer the structure.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m     \u001b[0mpeek\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m     \u001b[0massert_not_namedtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0mpeek\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpeek\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m_peek_and_restore\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    910\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_peek_and_restore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m   def _handle_multiprocessing(self, x, workers, use_multiprocessing,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     63\u001b[0m         index_array = self.index_array[self.batch_size * idx:\n\u001b[1;32m     64\u001b[0m                                        self.batch_size * (idx + 1)]\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_batches_of_transformed_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_array\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/iterator.py\u001b[0m in \u001b[0;36m_get_batches_of_transformed_samples\u001b[0;34m(self, index_array)\u001b[0m\n\u001b[1;32m    228\u001b[0m                            \u001b[0mcolor_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                            \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                            interpolation=self.interpolation)\n\u001b[0m\u001b[1;32m    231\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0;31m# Pillow images should be closed after `load_img`,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation)\u001b[0m\n\u001b[1;32m    111\u001b[0m         raise ImportError('Could not import PIL.Image. '\n\u001b[1;32m    112\u001b[0m                           'The use of `load_img` requires PIL.')\n\u001b[0;32m--> 113\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'grayscale'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'X-RayImageDataSet/Pneumonia/00010773_017.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ve1UJWmz_2XG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "42c536de-f24e-475c-e6cf-b927d8da7c17"
      },
      "source": [
        "print(\"Evaluate on test data\")\n",
        "results = model.evaluate(x_test, Y_test)\n",
        "print(\"test loss, test acc:\", results)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evaluate on test data\n",
            "8/8 [==============================] - 2s 200ms/step - loss: 0.8513 - accuracy: 0.7022\n",
            "test loss, test acc: [0.8512520790100098, 0.7022222280502319]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kEoOOh89L5MV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "a403b500-ac94-41d7-9477-c7743f1e4365"
      },
      "source": [
        "\n",
        "#  residual_block\n",
        "\n",
        "\n",
        "from keras.layers import Conv1D, Input, AveragePooling1D\n",
        "from keras.models import Model\n",
        "\n",
        "import keras\n",
        "#from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "#from keras import backend as K\n",
        "from keras.layers import Conv1D, MaxPooling1D\n",
        "from efficientnet import EfficientNetB3 as EfficientNetB3\n",
        "from efficientnet import center_crop_and_resize, preprocess_input\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "numpy.random.seed(seed)\n",
        "\n",
        "\n",
        "X_train  =  np.array(image_list)\n",
        "y_train  =  np.array(labels)\n",
        "\n",
        "\n",
        "print('x_train shape:', X_train.shape)\n",
        "print(X_train.shape[0], 'train samples')\n",
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "\n",
        "print(\"==============================\")\n",
        "\n",
        "num_classes = 3\n",
        "\n",
        "x_train = X_train.astype('float32')\n",
        "\n",
        "#x_train /= 255\n",
        "\n",
        "X =x_train.reshape(X_train.shape + (1,))\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "Y = y_train #keras.utils.to_categorical(y_train, num_classes)\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "# MLP for Pima Indians Dataset with 10-fold cross validation\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import StratifiedKFold\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (1125, 250, 250, 3)\n",
            "1125 train samples\n",
            "(1125, 250, 250, 3)\n",
            "(1125,)\n",
            "==============================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3hkUhQsXVZ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "98fa3c70-80d7-4595-80eb-d7e7ef0709b6"
      },
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from efficientnet import EfficientNetB3 as EfficientNetB2\n",
        "from keras.models import model_from_json\n",
        "import numpy\n",
        "import os\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
        "A = 1 \n",
        "\n",
        "cvscores = []\n",
        "for train, test in kfold.split(X, Y):\n",
        "  # create model\n",
        "  conv_base = EfficientNetB2(include_top=False, input_shape=input_shape, weights=\"imagenet\")\n",
        "  model = models.Sequential()\n",
        "  model.add(conv_base)\n",
        "  model.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n",
        "  #model.add(layers.Flatten(name=\"flatten\"))\n",
        "  dropout_rate =0.2\n",
        "  model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n",
        "  #model.add(layers.Dense(200, activation='relu', name=\"fc1\"))\n",
        "  model.add(layers.Dense(3, activation=\"softmax\", name=\"fc_out\"))\n",
        "\t# Compile model\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='RMSprop', metrics=['accuracy'])\n",
        "\t# Fit the model\n",
        "  YYtrain = keras.utils.to_categorical(Y[train], num_classes)\n",
        "  model.fit(X[train], YYtrain, epochs=40, batch_size=20, verbose=1)\n",
        "  print(X[train].shape)\n",
        "  print(YYtrain.shape)\n",
        "\t# evaluate the model\n",
        "  YYtest = keras.utils.to_categorical(Y[test], num_classes)\n",
        "  scores = model.evaluate(X[test], YYtest  , verbose=1)\n",
        "  print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
        "  print(X[test].shape)\n",
        "  print(YYtest.shape)\n",
        "  cvscores.append(scores[1] * 100)\n",
        "  test_pred = model.predict(X[test])\n",
        "  print(confusion_matrix(np.argmax(YYtest, axis=1),np.argmax(test_pred, axis=1)))\n",
        "  model_json = model.to_json()\n",
        "  with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "  # serialize weights to HDF5\n",
        "  model.save_weights(\"model\" + str(A) +\".h5\")\n",
        "  print(\"Saved model to disk\")\n",
        "  A = A+1\n",
        "  print(classification_report(np.argmax(YYtest, axis=1), np.argmax(test_pred, axis=1)))\n",
        "\n",
        "\n",
        "\n",
        "print(\"%.2f%% (+/- %.2f%%)\" % (numpy.mean(cvscores), numpy.std(cvscores)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b3_imagenet_1000_notop.h5\n",
            "43974656/43966704 [==============================] - 1s 0us/step\n",
            "Epoch 1/40\n",
            "45/45 [==============================] - 135s 3s/step - loss: 2.5894 - accuracy: 0.6633\n",
            "Epoch 2/40\n",
            "45/45 [==============================] - 129s 3s/step - loss: 1.1704 - accuracy: 0.7644\n",
            "Epoch 3/40\n",
            "45/45 [==============================] - 125s 3s/step - loss: 0.5843 - accuracy: 0.8333\n",
            "Epoch 4/40\n",
            "45/45 [==============================] - 124s 3s/step - loss: 0.5814 - accuracy: 0.8400\n",
            "Epoch 5/40\n",
            "45/45 [==============================] - 124s 3s/step - loss: 0.4159 - accuracy: 0.8622\n",
            "Epoch 6/40\n",
            "45/45 [==============================] - 124s 3s/step - loss: 0.3649 - accuracy: 0.8733\n",
            "Epoch 7/40\n",
            "45/45 [==============================] - 127s 3s/step - loss: 0.2655 - accuracy: 0.9011\n",
            "Epoch 8/40\n",
            "45/45 [==============================] - 126s 3s/step - loss: 0.2125 - accuracy: 0.9300\n",
            "Epoch 9/40\n",
            "45/45 [==============================] - 126s 3s/step - loss: 0.1813 - accuracy: 0.9467\n",
            "Epoch 10/40\n",
            "45/45 [==============================] - 126s 3s/step - loss: 0.2088 - accuracy: 0.9411\n",
            "Epoch 11/40\n",
            "45/45 [==============================] - 124s 3s/step - loss: 0.1608 - accuracy: 0.9578\n",
            "Epoch 12/40\n",
            "45/45 [==============================] - 126s 3s/step - loss: 0.1520 - accuracy: 0.9500\n",
            "Epoch 13/40\n",
            "45/45 [==============================] - 127s 3s/step - loss: 0.2745 - accuracy: 0.9478\n",
            "Epoch 14/40\n",
            "45/45 [==============================] - 129s 3s/step - loss: 0.1040 - accuracy: 0.9589\n",
            "Epoch 15/40\n",
            "45/45 [==============================] - 129s 3s/step - loss: 0.1804 - accuracy: 0.9578\n",
            "Epoch 16/40\n",
            "45/45 [==============================] - 129s 3s/step - loss: 0.0959 - accuracy: 0.9722\n",
            "Epoch 17/40\n",
            "45/45 [==============================] - 129s 3s/step - loss: 0.1100 - accuracy: 0.9778\n",
            "Epoch 18/40\n",
            "45/45 [==============================] - 129s 3s/step - loss: 0.1744 - accuracy: 0.9611\n",
            "Epoch 19/40\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.1256 - accuracy: 0.9700\n",
            "Epoch 20/40\n",
            "45/45 [==============================] - 127s 3s/step - loss: 0.0456 - accuracy: 0.9856\n",
            "Epoch 21/40\n",
            "45/45 [==============================] - 125s 3s/step - loss: 0.0702 - accuracy: 0.9856\n",
            "Epoch 22/40\n",
            "45/45 [==============================] - 124s 3s/step - loss: 0.0652 - accuracy: 0.9789\n",
            "Epoch 23/40\n",
            "45/45 [==============================] - 127s 3s/step - loss: 0.0775 - accuracy: 0.9811\n",
            "Epoch 24/40\n",
            "45/45 [==============================] - 132s 3s/step - loss: 0.1657 - accuracy: 0.9778\n",
            "Epoch 25/40\n",
            "45/45 [==============================] - 135s 3s/step - loss: 0.0822 - accuracy: 0.9744\n",
            "Epoch 26/40\n",
            "45/45 [==============================] - 132s 3s/step - loss: 0.0784 - accuracy: 0.9789\n",
            "Epoch 27/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.0494 - accuracy: 0.9878\n",
            "Epoch 28/40\n",
            "45/45 [==============================] - 132s 3s/step - loss: 0.0848 - accuracy: 0.9667\n",
            "Epoch 29/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.1167 - accuracy: 0.9800\n",
            "Epoch 30/40\n",
            "45/45 [==============================] - 134s 3s/step - loss: 0.0521 - accuracy: 0.9878\n",
            "Epoch 31/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.0590 - accuracy: 0.9867\n",
            "Epoch 32/40\n",
            "45/45 [==============================] - 126s 3s/step - loss: 0.0354 - accuracy: 0.9878\n",
            "Epoch 33/40\n",
            "45/45 [==============================] - 127s 3s/step - loss: 0.0536 - accuracy: 0.9922\n",
            "Epoch 34/40\n",
            "45/45 [==============================] - 126s 3s/step - loss: 0.1413 - accuracy: 0.9778\n",
            "Epoch 35/40\n",
            "45/45 [==============================] - 127s 3s/step - loss: 0.0445 - accuracy: 0.9867\n",
            "Epoch 36/40\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.0801 - accuracy: 0.9789\n",
            "Epoch 37/40\n",
            "45/45 [==============================] - 126s 3s/step - loss: 0.1178 - accuracy: 0.9800\n",
            "Epoch 38/40\n",
            "45/45 [==============================] - 125s 3s/step - loss: 0.0264 - accuracy: 0.9922\n",
            "Epoch 39/40\n",
            "45/45 [==============================] - 125s 3s/step - loss: 0.0638 - accuracy: 0.9878\n",
            "Epoch 40/40\n",
            "45/45 [==============================] - 129s 3s/step - loss: 0.0247 - accuracy: 0.9956\n",
            "(900, 250, 250, 3, 1)\n",
            "(900, 3)\n",
            "8/8 [==============================] - 4s 527ms/step - loss: 1.4053 - accuracy: 0.9022\n",
            "accuracy: 90.22%\n",
            "(225, 250, 250, 3, 1)\n",
            "(225, 3)\n",
            "[[24  1  0]\n",
            " [ 0 85 15]\n",
            " [ 0  6 94]]\n",
            "Saved model to disk\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.96      0.98        25\n",
            "           1       0.92      0.85      0.89       100\n",
            "           2       0.86      0.94      0.90       100\n",
            "\n",
            "    accuracy                           0.90       225\n",
            "   macro avg       0.93      0.92      0.92       225\n",
            "weighted avg       0.91      0.90      0.90       225\n",
            "\n",
            "Epoch 1/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 2.1573 - accuracy: 0.6856\n",
            "Epoch 2/40\n",
            "45/45 [==============================] - 132s 3s/step - loss: 0.8071 - accuracy: 0.8122\n",
            "Epoch 3/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.5545 - accuracy: 0.8211\n",
            "Epoch 4/40\n",
            "45/45 [==============================] - 133s 3s/step - loss: 0.5491 - accuracy: 0.8256\n",
            "Epoch 5/40\n",
            "45/45 [==============================] - 132s 3s/step - loss: 0.4066 - accuracy: 0.8544\n",
            "Epoch 6/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.4762 - accuracy: 0.8522\n",
            "Epoch 7/40\n",
            "45/45 [==============================] - 133s 3s/step - loss: 0.2754 - accuracy: 0.8922\n",
            "Epoch 8/40\n",
            "45/45 [==============================] - 130s 3s/step - loss: 0.3358 - accuracy: 0.8967\n",
            "Epoch 9/40\n",
            "45/45 [==============================] - 132s 3s/step - loss: 0.2382 - accuracy: 0.9200\n",
            "Epoch 10/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.1768 - accuracy: 0.9400\n",
            "Epoch 11/40\n",
            "45/45 [==============================] - 130s 3s/step - loss: 0.1626 - accuracy: 0.9533\n",
            "Epoch 12/40\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.1548 - accuracy: 0.9600\n",
            "Epoch 13/40\n",
            "45/45 [==============================] - 127s 3s/step - loss: 0.1178 - accuracy: 0.9600\n",
            "Epoch 14/40\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.1385 - accuracy: 0.9611\n",
            "Epoch 15/40\n",
            "45/45 [==============================] - 127s 3s/step - loss: 0.1329 - accuracy: 0.9622\n",
            "Epoch 16/40\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.1123 - accuracy: 0.9733\n",
            "Epoch 17/40\n",
            "45/45 [==============================] - 126s 3s/step - loss: 0.2045 - accuracy: 0.9422\n",
            "Epoch 18/40\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.1062 - accuracy: 0.9622\n",
            "Epoch 19/40\n",
            "45/45 [==============================] - 126s 3s/step - loss: 0.0716 - accuracy: 0.9778\n",
            "Epoch 20/40\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.0987 - accuracy: 0.9722\n",
            "Epoch 21/40\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.1193 - accuracy: 0.9667\n",
            "Epoch 22/40\n",
            "45/45 [==============================] - 127s 3s/step - loss: 0.0931 - accuracy: 0.9867\n",
            "Epoch 23/40\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.0706 - accuracy: 0.9833\n",
            "Epoch 24/40\n",
            "45/45 [==============================] - 127s 3s/step - loss: 0.0729 - accuracy: 0.9778\n",
            "Epoch 25/40\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.0710 - accuracy: 0.9822\n",
            "Epoch 26/40\n",
            "45/45 [==============================] - 127s 3s/step - loss: 0.0913 - accuracy: 0.9833\n",
            "Epoch 27/40\n",
            "45/45 [==============================] - 125s 3s/step - loss: 0.0844 - accuracy: 0.9789\n",
            "Epoch 28/40\n",
            "45/45 [==============================] - 130s 3s/step - loss: 0.0790 - accuracy: 0.9822\n",
            "Epoch 29/40\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.0373 - accuracy: 0.9844\n",
            "Epoch 30/40\n",
            "45/45 [==============================] - 129s 3s/step - loss: 0.0524 - accuracy: 0.9900\n",
            "Epoch 31/40\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.1449 - accuracy: 0.9811\n",
            "Epoch 32/40\n",
            "45/45 [==============================] - 130s 3s/step - loss: 0.1031 - accuracy: 0.9811\n",
            "Epoch 33/40\n",
            "45/45 [==============================] - 130s 3s/step - loss: 0.0659 - accuracy: 0.9822\n",
            "Epoch 34/40\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.0270 - accuracy: 0.9944\n",
            "Epoch 35/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.0248 - accuracy: 0.9922\n",
            "Epoch 36/40\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.0805 - accuracy: 0.9811\n",
            "Epoch 37/40\n",
            "45/45 [==============================] - 130s 3s/step - loss: 0.0631 - accuracy: 0.9800\n",
            "Epoch 38/40\n",
            "45/45 [==============================] - 129s 3s/step - loss: 0.0308 - accuracy: 0.9900\n",
            "Epoch 39/40\n",
            "45/45 [==============================] - 129s 3s/step - loss: 0.0300 - accuracy: 0.9911\n",
            "Epoch 40/40\n",
            "45/45 [==============================] - 128s 3s/step - loss: 0.1005 - accuracy: 0.9822\n",
            "(900, 250, 250, 3, 1)\n",
            "(900, 3)\n",
            "8/8 [==============================] - 4s 520ms/step - loss: 0.9872 - accuracy: 0.8933\n",
            "accuracy: 89.33%\n",
            "(225, 250, 250, 3, 1)\n",
            "(225, 3)\n",
            "[[22  1  2]\n",
            " [ 0 87 13]\n",
            " [ 0  8 92]]\n",
            "Saved model to disk\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.88      0.94        25\n",
            "           1       0.91      0.87      0.89       100\n",
            "           2       0.86      0.92      0.89       100\n",
            "\n",
            "    accuracy                           0.89       225\n",
            "   macro avg       0.92      0.89      0.90       225\n",
            "weighted avg       0.90      0.89      0.89       225\n",
            "\n",
            "Epoch 1/40\n",
            "45/45 [==============================] - 132s 3s/step - loss: 2.4956 - accuracy: 0.6578\n",
            "Epoch 2/40\n",
            "45/45 [==============================] - 133s 3s/step - loss: 0.9651 - accuracy: 0.7878\n",
            "Epoch 3/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.8004 - accuracy: 0.8056\n",
            "Epoch 4/40\n",
            "45/45 [==============================] - 132s 3s/step - loss: 0.6588 - accuracy: 0.8100\n",
            "Epoch 5/40\n",
            "45/45 [==============================] - 130s 3s/step - loss: 0.3296 - accuracy: 0.8756\n",
            "Epoch 6/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.4150 - accuracy: 0.8856\n",
            "Epoch 7/40\n",
            "45/45 [==============================] - 129s 3s/step - loss: 0.2696 - accuracy: 0.9033\n",
            "Epoch 8/40\n",
            "45/45 [==============================] - 130s 3s/step - loss: 0.2840 - accuracy: 0.9100\n",
            "Epoch 9/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.2234 - accuracy: 0.9144\n",
            "Epoch 10/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.1734 - accuracy: 0.9333\n",
            "Epoch 11/40\n",
            "45/45 [==============================] - 132s 3s/step - loss: 0.1942 - accuracy: 0.9444\n",
            "Epoch 12/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.1332 - accuracy: 0.9656\n",
            "Epoch 13/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.1478 - accuracy: 0.9578\n",
            "Epoch 14/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.1868 - accuracy: 0.9489\n",
            "Epoch 15/40\n",
            "45/45 [==============================] - 133s 3s/step - loss: 0.1171 - accuracy: 0.9578\n",
            "Epoch 16/40\n",
            "45/45 [==============================] - 134s 3s/step - loss: 0.0894 - accuracy: 0.9800\n",
            "Epoch 17/40\n",
            "45/45 [==============================] - 133s 3s/step - loss: 0.1030 - accuracy: 0.9711\n",
            "Epoch 18/40\n",
            "45/45 [==============================] - 133s 3s/step - loss: 0.1168 - accuracy: 0.9733\n",
            "Epoch 19/40\n",
            "45/45 [==============================] - 130s 3s/step - loss: 0.0903 - accuracy: 0.9744\n",
            "Epoch 20/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.1000 - accuracy: 0.9789\n",
            "Epoch 21/40\n",
            "45/45 [==============================] - 129s 3s/step - loss: 0.0841 - accuracy: 0.9778\n",
            "Epoch 22/40\n",
            "45/45 [==============================] - 130s 3s/step - loss: 0.1522 - accuracy: 0.9667\n",
            "Epoch 23/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.0382 - accuracy: 0.9878\n",
            "Epoch 24/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.1571 - accuracy: 0.9544\n",
            "Epoch 25/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.1238 - accuracy: 0.9678\n",
            "Epoch 26/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.0489 - accuracy: 0.9878\n",
            "Epoch 27/40\n",
            "45/45 [==============================] - 130s 3s/step - loss: 0.0857 - accuracy: 0.9778\n",
            "Epoch 28/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.0637 - accuracy: 0.9878\n",
            "Epoch 29/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.0307 - accuracy: 0.9900\n",
            "Epoch 30/40\n",
            "45/45 [==============================] - 133s 3s/step - loss: 0.0748 - accuracy: 0.9811\n",
            "Epoch 31/40\n",
            "45/45 [==============================] - 132s 3s/step - loss: 0.1057 - accuracy: 0.9856\n",
            "Epoch 32/40\n",
            "45/45 [==============================] - 133s 3s/step - loss: 0.1221 - accuracy: 0.9800\n",
            "Epoch 33/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.0113 - accuracy: 0.9989\n",
            "Epoch 34/40\n",
            "45/45 [==============================] - 132s 3s/step - loss: 0.0560 - accuracy: 0.9811\n",
            "Epoch 35/40\n",
            "45/45 [==============================] - 131s 3s/step - loss: 0.0548 - accuracy: 0.9867\n",
            "Epoch 36/40\n",
            "45/45 [==============================] - 130s 3s/step - loss: 0.0357 - accuracy: 0.9911\n",
            "Epoch 37/40\n",
            "45/45 [==============================] - 129s 3s/step - loss: 0.0167 - accuracy: 0.9944\n",
            "Epoch 38/40\n",
            "45/45 [==============================] - 130s 3s/step - loss: 0.0893 - accuracy: 0.9811\n",
            "Epoch 39/40\n",
            "45/45 [==============================] - 130s 3s/step - loss: 0.0350 - accuracy: 0.9911\n",
            "Epoch 40/40\n",
            "45/45 [==============================] - 129s 3s/step - loss: 0.0951 - accuracy: 0.9833\n",
            "(900, 250, 250, 3, 1)\n",
            "(900, 3)\n",
            "8/8 [==============================] - 4s 513ms/step - loss: 1.0459 - accuracy: 0.9111\n",
            "accuracy: 91.11%\n",
            "(225, 250, 250, 3, 1)\n",
            "(225, 3)\n",
            "[[21  2  2]\n",
            " [ 0 88 12]\n",
            " [ 0  4 96]]\n",
            "Saved model to disk\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.84      0.91        25\n",
            "           1       0.94      0.88      0.91       100\n",
            "           2       0.87      0.96      0.91       100\n",
            "\n",
            "    accuracy                           0.91       225\n",
            "   macro avg       0.94      0.89      0.91       225\n",
            "weighted avg       0.92      0.91      0.91       225\n",
            "\n",
            "Epoch 1/40\n",
            "45/45 [==============================] - 126s 3s/step - loss: 3.0325 - accuracy: 0.6644\n",
            "Epoch 2/40\n",
            "45/45 [==============================] - 125s 3s/step - loss: 0.9216 - accuracy: 0.7733\n",
            "Epoch 3/40\n",
            "45/45 [==============================] - 127s 3s/step - loss: 0.5250 - accuracy: 0.8156\n",
            "Epoch 4/40\n",
            "45/45 [==============================] - 126s 3s/step - loss: 0.4536 - accuracy: 0.8356\n",
            "Epoch 5/40\n",
            "45/45 [==============================] - 124s 3s/step - loss: 0.3364 - accuracy: 0.8778\n",
            "Epoch 6/40\n",
            "45/45 [==============================] - 124s 3s/step - loss: 0.3241 - accuracy: 0.8867\n",
            "Epoch 7/40\n",
            "45/45 [==============================] - 123s 3s/step - loss: 0.3327 - accuracy: 0.9044\n",
            "Epoch 8/40\n",
            "45/45 [==============================] - 123s 3s/step - loss: 0.2193 - accuracy: 0.9300\n",
            "Epoch 9/40\n",
            "45/45 [==============================] - 123s 3s/step - loss: 0.2122 - accuracy: 0.9200\n",
            "Epoch 10/40\n",
            "45/45 [==============================] - 123s 3s/step - loss: 0.1800 - accuracy: 0.9422\n",
            "Epoch 11/40\n",
            "45/45 [==============================] - 123s 3s/step - loss: 0.1204 - accuracy: 0.9567\n",
            "Epoch 12/40\n",
            "45/45 [==============================] - 123s 3s/step - loss: 0.1395 - accuracy: 0.9589\n",
            "Epoch 13/40\n",
            "45/45 [==============================] - 123s 3s/step - loss: 0.1944 - accuracy: 0.9411\n",
            "Epoch 14/40\n",
            "45/45 [==============================] - 121s 3s/step - loss: 0.1863 - accuracy: 0.9400\n",
            "Epoch 15/40\n",
            "45/45 [==============================] - 120s 3s/step - loss: 0.1404 - accuracy: 0.9600\n",
            "Epoch 16/40\n",
            "45/45 [==============================] - 120s 3s/step - loss: 0.1213 - accuracy: 0.9644\n",
            "Epoch 17/40\n",
            "45/45 [==============================] - 119s 3s/step - loss: 0.0709 - accuracy: 0.9800\n",
            "Epoch 18/40\n",
            "45/45 [==============================] - 119s 3s/step - loss: 0.0762 - accuracy: 0.9767\n",
            "Epoch 19/40\n",
            "45/45 [==============================] - 117s 3s/step - loss: 0.1259 - accuracy: 0.9744\n",
            "Epoch 20/40\n",
            "45/45 [==============================] - 120s 3s/step - loss: 0.0562 - accuracy: 0.9789\n",
            "Epoch 21/40\n",
            "45/45 [==============================] - 120s 3s/step - loss: 0.0960 - accuracy: 0.9678\n",
            "Epoch 22/40\n",
            "45/45 [==============================] - 119s 3s/step - loss: 0.0689 - accuracy: 0.9833\n",
            "Epoch 23/40\n",
            "45/45 [==============================] - 119s 3s/step - loss: 0.0680 - accuracy: 0.9778\n",
            "Epoch 24/40\n",
            "45/45 [==============================] - 120s 3s/step - loss: 0.0654 - accuracy: 0.9822\n",
            "Epoch 25/40\n",
            "45/45 [==============================] - 120s 3s/step - loss: 0.0286 - accuracy: 0.9878\n",
            "Epoch 26/40\n",
            "45/45 [==============================] - 120s 3s/step - loss: 0.0701 - accuracy: 0.9767\n",
            "Epoch 27/40\n",
            "45/45 [==============================] - 119s 3s/step - loss: 0.0592 - accuracy: 0.9867\n",
            "Epoch 28/40\n",
            "45/45 [==============================] - 119s 3s/step - loss: 0.0449 - accuracy: 0.9922\n",
            "Epoch 29/40\n",
            "45/45 [==============================] - 118s 3s/step - loss: 0.0409 - accuracy: 0.9900\n",
            "Epoch 30/40\n",
            "45/45 [==============================] - 117s 3s/step - loss: 0.0628 - accuracy: 0.9856\n",
            "Epoch 31/40\n",
            "45/45 [==============================] - 119s 3s/step - loss: 0.0486 - accuracy: 0.9889\n",
            "Epoch 32/40\n",
            "45/45 [==============================] - 118s 3s/step - loss: 0.0222 - accuracy: 0.9922\n",
            "Epoch 33/40\n",
            "45/45 [==============================] - 117s 3s/step - loss: 0.0544 - accuracy: 0.9878\n",
            "Epoch 34/40\n",
            "45/45 [==============================] - 118s 3s/step - loss: 0.0385 - accuracy: 0.9922\n",
            "Epoch 35/40\n",
            "45/45 [==============================] - 119s 3s/step - loss: 0.0125 - accuracy: 0.9967\n",
            "Epoch 36/40\n",
            "45/45 [==============================] - 118s 3s/step - loss: 0.1188 - accuracy: 0.9867\n",
            "Epoch 37/40\n",
            "45/45 [==============================] - 117s 3s/step - loss: 0.0509 - accuracy: 0.9822\n",
            "Epoch 38/40\n",
            "45/45 [==============================] - 119s 3s/step - loss: 0.0329 - accuracy: 0.9889\n",
            "Epoch 39/40\n",
            "45/45 [==============================] - 119s 3s/step - loss: 0.0409 - accuracy: 0.9867\n",
            "Epoch 40/40\n",
            "45/45 [==============================] - 117s 3s/step - loss: 0.0531 - accuracy: 0.9889\n",
            "(900, 250, 250, 3, 1)\n",
            "(900, 3)\n",
            "8/8 [==============================] - 4s 491ms/step - loss: 1.1366 - accuracy: 0.8844\n",
            "accuracy: 88.44%\n",
            "(225, 250, 250, 3, 1)\n",
            "(225, 3)\n",
            "[[23  2  0]\n",
            " [ 0 87 13]\n",
            " [ 0 11 89]]\n",
            "Saved model to disk\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.92      0.96        25\n",
            "           1       0.87      0.87      0.87       100\n",
            "           2       0.87      0.89      0.88       100\n",
            "\n",
            "    accuracy                           0.88       225\n",
            "   macro avg       0.91      0.89      0.90       225\n",
            "weighted avg       0.89      0.88      0.88       225\n",
            "\n",
            "Epoch 1/40\n",
            "45/45 [==============================] - 115s 3s/step - loss: 2.3824 - accuracy: 0.6644\n",
            "Epoch 2/40\n",
            "45/45 [==============================] - 112s 2s/step - loss: 0.9324 - accuracy: 0.7544\n",
            "Epoch 3/40\n",
            "45/45 [==============================] - 114s 3s/step - loss: 0.6345 - accuracy: 0.8011\n",
            "Epoch 4/40\n",
            "45/45 [==============================] - 114s 3s/step - loss: 0.4870 - accuracy: 0.8456\n",
            "Epoch 5/40\n",
            "45/45 [==============================] - 115s 3s/step - loss: 0.3866 - accuracy: 0.8511\n",
            "Epoch 6/40\n",
            "45/45 [==============================] - 115s 3s/step - loss: 0.3507 - accuracy: 0.8900\n",
            "Epoch 7/40\n",
            "45/45 [==============================] - 111s 2s/step - loss: 0.2373 - accuracy: 0.9189\n",
            "Epoch 8/40\n",
            "45/45 [==============================] - 113s 3s/step - loss: 0.3147 - accuracy: 0.8833\n",
            "Epoch 9/40\n",
            "45/45 [==============================] - 112s 2s/step - loss: 0.2294 - accuracy: 0.9244\n",
            "Epoch 10/40\n",
            "45/45 [==============================] - 113s 3s/step - loss: 0.1649 - accuracy: 0.9444\n",
            "Epoch 11/40\n",
            "45/45 [==============================] - 111s 2s/step - loss: 0.2237 - accuracy: 0.9467\n",
            "Epoch 12/40\n",
            "45/45 [==============================] - 112s 2s/step - loss: 0.1735 - accuracy: 0.9411\n",
            "Epoch 13/40\n",
            "45/45 [==============================] - 110s 2s/step - loss: 0.1624 - accuracy: 0.9489\n",
            "Epoch 14/40\n",
            "45/45 [==============================] - 111s 2s/step - loss: 0.1037 - accuracy: 0.9700\n",
            "Epoch 15/40\n",
            "45/45 [==============================] - 110s 2s/step - loss: 0.0869 - accuracy: 0.9722\n",
            "Epoch 16/40\n",
            "45/45 [==============================] - 111s 2s/step - loss: 0.1762 - accuracy: 0.9667\n",
            "Epoch 17/40\n",
            "45/45 [==============================] - 112s 2s/step - loss: 0.0696 - accuracy: 0.9733\n",
            "Epoch 18/40\n",
            "45/45 [==============================] - 111s 2s/step - loss: 0.0911 - accuracy: 0.9711\n",
            "Epoch 19/40\n",
            "45/45 [==============================] - 111s 2s/step - loss: 0.0780 - accuracy: 0.9744\n",
            "Epoch 20/40\n",
            "45/45 [==============================] - 111s 2s/step - loss: 0.0541 - accuracy: 0.9867\n",
            "Epoch 21/40\n",
            "45/45 [==============================] - 111s 2s/step - loss: 0.0640 - accuracy: 0.9744\n",
            "Epoch 22/40\n",
            "45/45 [==============================] - 111s 2s/step - loss: 0.1587 - accuracy: 0.9778\n",
            "Epoch 23/40\n",
            "45/45 [==============================] - 112s 2s/step - loss: 0.0996 - accuracy: 0.9822\n",
            "Epoch 24/40\n",
            "45/45 [==============================] - 112s 2s/step - loss: 0.0526 - accuracy: 0.9833\n",
            "Epoch 25/40\n",
            "45/45 [==============================] - 112s 2s/step - loss: 0.1020 - accuracy: 0.9867\n",
            "Epoch 26/40\n",
            "45/45 [==============================] - 112s 2s/step - loss: 0.0792 - accuracy: 0.9844\n",
            "Epoch 27/40\n",
            "45/45 [==============================] - 111s 2s/step - loss: 0.0404 - accuracy: 0.9889\n",
            "Epoch 28/40\n",
            "45/45 [==============================] - 113s 3s/step - loss: 0.0911 - accuracy: 0.9800\n",
            "Epoch 29/40\n",
            "45/45 [==============================] - 111s 2s/step - loss: 0.1558 - accuracy: 0.9811\n",
            "Epoch 30/40\n",
            "45/45 [==============================] - 112s 2s/step - loss: 0.0335 - accuracy: 0.9889\n",
            "Epoch 31/40\n",
            "45/45 [==============================] - 114s 3s/step - loss: 0.0796 - accuracy: 0.9878\n",
            "Epoch 32/40\n",
            "45/45 [==============================] - 112s 2s/step - loss: 0.0495 - accuracy: 0.9867\n",
            "Epoch 33/40\n",
            "45/45 [==============================] - 114s 3s/step - loss: 0.0773 - accuracy: 0.9722\n",
            "Epoch 34/40\n",
            "45/45 [==============================] - 111s 2s/step - loss: 0.0519 - accuracy: 0.9900\n",
            "Epoch 35/40\n",
            "45/45 [==============================] - 110s 2s/step - loss: 0.0925 - accuracy: 0.9800\n",
            "Epoch 36/40\n",
            "45/45 [==============================] - 110s 2s/step - loss: 0.0085 - accuracy: 0.9967\n",
            "Epoch 37/40\n",
            "45/45 [==============================] - 110s 2s/step - loss: 0.0357 - accuracy: 0.9911\n",
            "Epoch 38/40\n",
            "45/45 [==============================] - 111s 2s/step - loss: 0.0580 - accuracy: 0.9867\n",
            "Epoch 39/40\n",
            "45/45 [==============================] - 113s 3s/step - loss: 0.0879 - accuracy: 0.9833\n",
            "Epoch 40/40\n",
            "45/45 [==============================] - 113s 3s/step - loss: 0.0292 - accuracy: 0.9900\n",
            "(900, 250, 250, 3, 1)\n",
            "(900, 3)\n",
            "8/8 [==============================] - 4s 496ms/step - loss: 1.5565 - accuracy: 0.8889\n",
            "accuracy: 88.89%\n",
            "(225, 250, 250, 3, 1)\n",
            "(225, 3)\n",
            "[[23  2  0]\n",
            " [ 0 89 11]\n",
            " [ 0 12 88]]\n",
            "Saved model to disk\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.92      0.96        25\n",
            "           1       0.86      0.89      0.88       100\n",
            "           2       0.89      0.88      0.88       100\n",
            "\n",
            "    accuracy                           0.89       225\n",
            "   macro avg       0.92      0.90      0.91       225\n",
            "weighted avg       0.89      0.89      0.89       225\n",
            "\n",
            "89.60% (+/- 0.96%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8MOIjmqz2lkE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4e0cbf0b-6240-42dd-9062-c72e57c47e56"
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   2,    3,    4,    5,    6,    7,    8,   10,   11,   12,   13,\n",
              "         14,   16,   17,   19,   22,   23,   24,   25,   27,   28,   29,\n",
              "         31,   32,   33,   34,   35,   37,   38,   39,   40,   41,   42,\n",
              "         43,   44,   45,   46,   47,   48,   49,   50,   51,   52,   53,\n",
              "         55,   56,   57,   59,   60,   61,   63,   64,   66,   67,   68,\n",
              "         69,   71,   72,   73,   74,   75,   79,   80,   81,   82,   83,\n",
              "         84,   85,   86,   87,   88,   89,   90,   91,   92,   93,   95,\n",
              "         96,   97,   98,   99,  100,  101,  102,  103,  106,  107,  108,\n",
              "        109,  111,  112,  114,  115,  116,  118,  119,  120,  122,  123,\n",
              "        124,  126,  129,  130,  132,  133,  134,  137,  139,  140,  141,\n",
              "        142,  143,  144,  145,  147,  149,  150,  151,  152,  153,  154,\n",
              "        155,  156,  157,  159,  160,  161,  162,  163,  164,  165,  167,\n",
              "        168,  169,  171,  172,  173,  174,  176,  177,  179,  180,  181,\n",
              "        182,  183,  184,  185,  186,  187,  188,  190,  192,  193,  194,\n",
              "        195,  196,  197,  199,  203,  205,  206,  207,  208,  211,  212,\n",
              "        213,  214,  215,  216,  217,  218,  220,  222,  223,  224,  225,\n",
              "        226,  227,  228,  229,  230,  231,  232,  233,  235,  236,  238,\n",
              "        239,  240,  241,  242,  243,  244,  245,  246,  247,  248,  249,\n",
              "        250,  251,  252,  253,  254,  255,  256,  257,  259,  261,  262,\n",
              "        263,  264,  265,  266,  267,  268,  269,  270,  272,  274,  275,\n",
              "        276,  277,  279,  280,  282,  283,  287,  288,  289,  290,  292,\n",
              "        293,  294,  295,  297,  299,  301,  302,  303,  304,  305,  306,\n",
              "        307,  308,  309,  310,  311,  312,  313,  314,  315,  316,  317,\n",
              "        318,  319,  320,  322,  323,  326,  327,  328,  329,  330,  331,\n",
              "        333,  334,  335,  337,  338,  339,  340,  341,  342,  343,  345,\n",
              "        346,  347,  348,  349,  351,  352,  353,  355,  356,  357,  358,\n",
              "        359,  361,  362,  364,  367,  368,  369,  370,  372,  373,  374,\n",
              "        375,  376,  377,  378,  379,  380,  381,  382,  383,  384,  385,\n",
              "        386,  387,  388,  389,  390,  391,  393,  394,  395,  396,  397,\n",
              "        398,  399,  400,  401,  403,  404,  405,  406,  408,  409,  410,\n",
              "        411,  412,  413,  414,  416,  417,  419,  420,  422,  423,  425,\n",
              "        426,  428,  429,  430,  432,  433,  434,  435,  436,  437,  438,\n",
              "        439,  440,  441,  442,  444,  445,  448,  449,  451,  452,  453,\n",
              "        455,  456,  457,  458,  459,  460,  462,  463,  465,  466,  467,\n",
              "        468,  471,  472,  474,  475,  476,  477,  480,  481,  482,  483,\n",
              "        484,  485,  487,  488,  489,  490,  492,  494,  495,  496,  497,\n",
              "        498,  499,  500,  502,  503,  504,  505,  506,  507,  508,  509,\n",
              "        510,  511,  512,  513,  514,  515,  516,  517,  520,  521,  522,\n",
              "        523,  524,  525,  527,  529,  530,  531,  533,  534,  535,  536,\n",
              "        537,  541,  542,  543,  544,  545,  546,  548,  549,  551,  552,\n",
              "        553,  554,  555,  556,  557,  558,  561,  562,  563,  564,  565,\n",
              "        566,  567,  568,  570,  572,  574,  575,  576,  577,  578,  579,\n",
              "        580,  581,  582,  583,  584,  585,  586,  587,  588,  589,  590,\n",
              "        591,  594,  595,  596,  597,  599,  600,  601,  602,  603,  604,\n",
              "        605,  606,  607,  610,  611,  612,  613,  614,  615,  616,  617,\n",
              "        618,  619,  621,  622,  623,  625,  626,  627,  628,  629,  630,\n",
              "        631,  633,  635,  637,  638,  639,  641,  642,  644,  645,  646,\n",
              "        647,  649,  650,  652,  653,  654,  655,  657,  658,  659,  660,\n",
              "        661,  662,  663,  664,  665,  666,  667,  668,  669,  672,  674,\n",
              "        675,  676,  677,  679,  680,  681,  682,  683,  684,  685,  688,\n",
              "        689,  690,  692,  693,  694,  695,  696,  697,  698,  699,  700,\n",
              "        701,  702,  703,  704,  705,  707,  708,  709,  710,  711,  712,\n",
              "        714,  715,  717,  718,  719,  721,  722,  725,  727,  728,  729,\n",
              "        730,  731,  733,  734,  735,  736,  737,  738,  739,  740,  741,\n",
              "        743,  745,  746,  748,  749,  750,  751,  752,  753,  755,  756,\n",
              "        757,  758,  760,  761,  762,  763,  764,  765,  767,  768,  769,\n",
              "        770,  771,  773,  774,  775,  776,  778,  779,  781,  782,  783,\n",
              "        784,  785,  786,  787,  789,  791,  792,  793,  794,  796,  797,\n",
              "        799,  800,  802,  803,  804,  805,  806,  807,  808,  809,  810,\n",
              "        811,  813,  814,  815,  816,  818,  819,  820,  821,  822,  823,\n",
              "        825,  826,  827,  828,  829,  830,  832,  834,  835,  836,  837,\n",
              "        838,  839,  840,  841,  842,  843,  844,  845,  846,  848,  849,\n",
              "        850,  852,  853,  857,  858,  859,  861,  862,  863,  864,  865,\n",
              "        866,  867,  868,  869,  870,  872,  873,  874,  875,  876,  877,\n",
              "        878,  879,  880,  881,  882,  883,  884,  885,  886,  887,  888,\n",
              "        889,  890,  891,  893,  895,  896,  897,  898,  899,  901,  902,\n",
              "        903,  904,  905,  907,  908,  910,  911,  912,  914,  915,  916,\n",
              "        917,  920,  921,  924,  925,  929,  930,  931,  932,  933,  934,\n",
              "        935,  936,  937,  938,  939,  940,  941,  942,  944,  945,  946,\n",
              "        948,  949,  952,  953,  954,  957,  958,  959,  962,  964,  965,\n",
              "        967,  968,  969,  970,  971,  972,  973,  974,  975,  976,  977,\n",
              "        978,  979,  980,  982,  983,  984,  986,  987,  989,  990,  991,\n",
              "        992,  993,  994,  995,  996,  997,  998,  999, 1001, 1002, 1003,\n",
              "       1005, 1006, 1007, 1008, 1009, 1010, 1011, 1013, 1014, 1016, 1017,\n",
              "       1018, 1019, 1020, 1021, 1022, 1023, 1028, 1029, 1030, 1032, 1034,\n",
              "       1035, 1036, 1037, 1038, 1039, 1041, 1042, 1043, 1044, 1046, 1047,\n",
              "       1048, 1049, 1050, 1051, 1052, 1053, 1054, 1055, 1059, 1060, 1062,\n",
              "       1063, 1064, 1065, 1066, 1067, 1068, 1069, 1070, 1071, 1072, 1073,\n",
              "       1075, 1076, 1077, 1078, 1080, 1082, 1083, 1084, 1085, 1086, 1087,\n",
              "       1088, 1089, 1090, 1091, 1092, 1093, 1094, 1095, 1096, 1097, 1098,\n",
              "       1101, 1103, 1104, 1106, 1107, 1108, 1109, 1110, 1112, 1113, 1114,\n",
              "       1115, 1116, 1117, 1118, 1119, 1120, 1121, 1122, 1124])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nK5yG8hOh3P-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "c53674ea-685a-46fd-ede3-3c906bb97624"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-46ba630259cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: confusion_matrix() missing 1 required positional argument: 'y_pred'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTmyk0-JhZ6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import plot_model\n",
        "plot_model(conv_base, to_file='conv_base.png', show_shapes=True)\n",
        "from IPython.display import Image\n",
        "Image(filename='conv_base.png') \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6m72gKamWNY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "23e9871e-1c8d-4b4a-ab6a-0961e2a514b1"
      },
      "source": [
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "test_pred =   [[21,  3,  1]\n",
        "              [ 0, 87, 13]\n",
        "              [ 0, 10, 90]]\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "#test_pred = model.predict(x_test)\n",
        "ax = sns.heatmap(confusion_matrix(np.argmax(Y_test, axis=1),np.argmax(test_pred, axis=1)), cmap=\"binary\",annot=True,fmt=\"d\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-30a77d3b1a55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m test_pred =   [[21,  3,  1]\n\u001b[0;32m----> 5\u001b[0;31m               \u001b[0;34m[\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m87\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m13\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m               [ 0, 10, 90]]\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyZgv4Nm2gg6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "7a7f3f01-8d76-444e-9657-d95699b7d453"
      },
      "source": [
        "confusion_matrix(np.argmax(Y_test, axis=1),np.argmax(test_pred, axis=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[26,  3,  0],\n",
              "       [ 1, 82, 20],\n",
              "       [ 1,  5, 87]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50eymI_11wcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "target_names =  [\"Covid19\" ,\"Pneumonia\" , \"No finding\"]\n",
        "def plot_confusion_matrix(cm, title='Confusion matrix', cmap=plt.cm.Blues):\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(target_names))\n",
        "    plt.xticks(tick_marks, target_names, rotation=45)\n",
        "    plt.yticks(tick_marks, target_names)\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "cm = model.predict(x_test)\n",
        "\n",
        "print('Confusion matrix, without normalization')\n",
        "print(cm)\n",
        "plt.figure()\n",
        "plot_confusion_matrix(cm)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHUMfSt1ysNm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import model_from_json\n",
        "# serialize model to JSON\n",
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "# serialize weights to HDF5\n",
        "model.save_weights(\"modelEfficientNet.h5\")\n",
        "print(\"Saved model to disk\")\n",
        "\n",
        "# later...\n",
        "\n",
        "# load json and create model\n",
        "#json_file = open('modelEfficientNet.json', 'r')\n",
        "#loaded_model_json = json_file.read()\n",
        "#json_file.close() \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}